{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o8Y3jiOrPwOf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download Pretrained Weights and Install Packages\n",
        "#for kaggle fix this line\n",
        "%cd /content/\n",
        "!rm -rf ./LivePortrait\n",
        "!git clone https://github.com/KwaiVGI/LivePortrait.git\n",
        "\n",
        "from tqdm import tqdm\n",
        "import urllib\n",
        "import os\n",
        "import shutil\n",
        "def conditional_download(url, download_file_path):\n",
        "    print(f\"Downloading {os.path.basename(download_file_path)}\")\n",
        "    base_path = os.path.dirname(download_file_path)\n",
        "\n",
        "    if not os.path.exists(base_path):\n",
        "        os.makedirs(base_path)\n",
        "\n",
        "    if os.path.exists(download_file_path):\n",
        "        os.remove(download_file_path)\n",
        "\n",
        "    try:\n",
        "        request = urllib.request.urlopen(url)  # type: ignore[attr-defined]\n",
        "        total = int(request.headers.get('Content-Length', 0))\n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"Error: Unable to open the URL - {url}\")\n",
        "        print(f\"Reason: {e.reason}\")\n",
        "        return\n",
        "\n",
        "    with tqdm(total=total, desc='Downloading', unit='B', unit_scale=True, unit_divisor=1024) as progress:\n",
        "        try:\n",
        "            urllib.request.urlretrieve(url, download_file_path, reporthook=lambda count, block_size, total_size: progress.update(block_size))  # type: ignore[attr-defined]\n",
        "        except urllib.error.URLError as e:\n",
        "            print(f\"Error: Failed to download the file from the URL - {url}\")\n",
        "            print(f\"Reason: {e.reason}\")\n",
        "            return\n",
        "\n",
        "    print(f\"Download successful!\")\n",
        "    print(f\"URL: {url}\")\n",
        "    print(f\"Save at: {download_file_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def download_models(base_path):\n",
        "    # Function to download files\n",
        "    def download_files(file_list, relative_path, base_url):\n",
        "        for file_name in file_list:\n",
        "            download_file_path = f\"{base_path}/{relative_path}/{file_name}\"\n",
        "            conditional_download(f\"{base_url}/{file_name}\", download_file_path)\n",
        "\n",
        "    # Define file lists and paths\n",
        "    buffalo_l_files = [\"2d106det.onnx\", \"det_10g.onnx\"]\n",
        "    buffalo_l_path = \"LivePortrait/pretrained_weights/insightface/models/buffalo_l\"\n",
        "    buffalo_l_url = \"https://huggingface.co/KwaiVGI/LivePortrait/resolve/main/insightface/models/buffalo_l\"\n",
        "\n",
        "    base_models_files = [\n",
        "        'appearance_feature_extractor.pth',\n",
        "        'motion_extractor.pth',\n",
        "        'spade_generator.pth',\n",
        "        'warping_module.pth'\n",
        "    ]\n",
        "    base_models_path = \"LivePortrait/pretrained_weights/liveportrait/base_models\"\n",
        "    base_models_url = \"https://huggingface.co/KwaiVGI/LivePortrait/resolve/main/liveportrait/base_models\"\n",
        "\n",
        "    retargeting_models_files = ['stitching_retargeting_module.pth']\n",
        "    retargeting_models_path = \"LivePortrait/pretrained_weights/liveportrait/retargeting_models\"\n",
        "    retargeting_models_url = \"https://huggingface.co/KwaiVGI/LivePortrait/resolve/main/liveportrait/retargeting_models\"\n",
        "\n",
        "    landmark_file = [\"landmark.onnx\"]\n",
        "    landmark_path = \"LivePortrait/pretrained_weights/liveportrait\"\n",
        "    landmark_url = \"https://huggingface.co/KwaiVGI/LivePortrait/resolve/main/liveportrait\"\n",
        "\n",
        "    # Download files\n",
        "    download_files(buffalo_l_files, buffalo_l_path, buffalo_l_url)\n",
        "    download_files(base_models_files, base_models_path, base_models_url)\n",
        "    download_files(retargeting_models_files, retargeting_models_path, retargeting_models_url)\n",
        "    download_files(landmark_file, landmark_path, landmark_url)\n",
        "\n",
        "#set up base_path\n",
        "import os\n",
        "root_path=os.getcwd()\n",
        "# root_path=\"/content\"\n",
        "base_path=f\"{root_path}\"\n",
        "#download model\n",
        "download_models(base_path)\n",
        "os.chdir(f\"{base_path}/LivePortrait\")\n",
        "!pip install -r requirements.txt\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Gradio app\n",
        "%cd /content/LivePortrait\n",
        "import tyro\n",
        "import gradio as gr\n",
        "import os.path as osp\n",
        "from src.utils.helper import load_description\n",
        "from src.gradio_pipeline import GradioPipeline\n",
        "from src.config.crop_config import CropConfig\n",
        "from src.config.argument_config import ArgumentConfig\n",
        "from src.config.inference_config import InferenceConfig\n",
        "\n",
        "def partial_fields(target_class, kwargs):\n",
        "    return target_class(**{k: v for k, v in kwargs.items() if hasattr(target_class, k)})\n",
        "\n",
        "# Set default values for ArgumentConfig\n",
        "default_args = {\n",
        "    \"server_name\": \"0.0.0.0\",\n",
        "    \"server_port\": 7860,\n",
        "    \"share\": True,\n",
        "    # Add other default values as needed\n",
        "}\n",
        "\n",
        "# Create an args object with default values\n",
        "args = ArgumentConfig(**default_args)\n",
        "\n",
        "# specify configs for inference\n",
        "inference_cfg = partial_fields(InferenceConfig, args.__dict__)  # use attribute of args to initial InferenceConfig\n",
        "crop_cfg = partial_fields(CropConfig, args.__dict__)  # use attribute of args to initial CropConfig\n",
        "gradio_pipeline = GradioPipeline(\n",
        "    inference_cfg=inference_cfg,\n",
        "    crop_cfg=crop_cfg,\n",
        "    args=args\n",
        ")\n",
        "# assets\n",
        "title_md = \"assets/gradio_title.md\"\n",
        "example_portrait_dir = \"assets/examples/source\"\n",
        "example_video_dir = \"assets/examples/driving\"\n",
        "data_examples = [\n",
        "    [osp.join(example_portrait_dir, \"s9.jpg\"), osp.join(example_video_dir, \"d0.mp4\"), True, True, True, True],\n",
        "    [osp.join(example_portrait_dir, \"s6.jpg\"), osp.join(example_video_dir, \"d0.mp4\"), True, True, True, True],\n",
        "    [osp.join(example_portrait_dir, \"s10.jpg\"), osp.join(example_video_dir, \"d5.mp4\"), True, True, True, True],\n",
        "    [osp.join(example_portrait_dir, \"s5.jpg\"), osp.join(example_video_dir, \"d6.mp4\"), True, True, True, True],\n",
        "    [osp.join(example_portrait_dir, \"s7.jpg\"), osp.join(example_video_dir, \"d7.mp4\"), True, True, True, True],\n",
        "]\n",
        "#################### interface logic ####################\n",
        "\n",
        "# Define components first\n",
        "eye_retargeting_slider = gr.Slider(minimum=0, maximum=0.8, step=0.01, label=\"target eyes-open ratio\")\n",
        "lip_retargeting_slider = gr.Slider(minimum=0, maximum=0.8, step=0.01, label=\"target lip-open ratio\")\n",
        "retargeting_input_image = gr.Image(type=\"numpy\")\n",
        "output_image = gr.Image(type=\"numpy\")\n",
        "output_image_paste_back = gr.Image(type=\"numpy\")\n",
        "output_video = gr.Video()\n",
        "output_video_concat = gr.Video()\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.HTML(load_description(title_md))\n",
        "    gr.Markdown(load_description(\"assets/gradio_description_upload.md\"))\n",
        "    with gr.Row():\n",
        "        with gr.Accordion(open=True, label=\"Source Portrait\"):\n",
        "            image_input = gr.Image(type=\"filepath\")\n",
        "        with gr.Accordion(open=True, label=\"Driving Video\"):\n",
        "            video_input = gr.Video()\n",
        "    gr.Markdown(load_description(\"assets/gradio_description_animation.md\"))\n",
        "    with gr.Row():\n",
        "        with gr.Accordion(open=True, label=\"Animation Options\"):\n",
        "            with gr.Row():\n",
        "                flag_relative_input = gr.Checkbox(value=True, label=\"relative motion\")\n",
        "                flag_do_crop_input = gr.Checkbox(value=True, label=\"do crop\")\n",
        "                flag_remap_input = gr.Checkbox(value=True, label=\"paste-back\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            process_button_animation = gr.Button(\"🚀 Animate\", variant=\"primary\")\n",
        "        with gr.Column():\n",
        "            process_button_reset = gr.ClearButton([image_input, video_input, output_video, output_video_concat], value=\"🧹 Clear\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            with gr.Accordion(open=True, label=\"The animated video in the original image space\"):\n",
        "                output_video.render()\n",
        "        with gr.Column():\n",
        "            with gr.Accordion(open=True, label=\"The animated video\"):\n",
        "                output_video_concat.render()\n",
        "    with gr.Row():\n",
        "        # Examples\n",
        "        gr.Markdown(\"## You could choose the examples below ⬇️\")\n",
        "    with gr.Row():\n",
        "        gr.Examples(\n",
        "            examples=data_examples,\n",
        "            inputs=[\n",
        "                image_input,\n",
        "                video_input,\n",
        "                flag_relative_input,\n",
        "                flag_do_crop_input,\n",
        "                flag_remap_input\n",
        "            ],\n",
        "            examples_per_page=5\n",
        "        )\n",
        "    gr.Markdown(load_description(\"assets/gradio_description_retargeting.md\"))\n",
        "    with gr.Row():\n",
        "        eye_retargeting_slider.render()\n",
        "        lip_retargeting_slider.render()\n",
        "    with gr.Row():\n",
        "        process_button_retargeting = gr.Button(\"🚗 Retargeting\", variant=\"primary\")\n",
        "        process_button_reset_retargeting = gr.ClearButton(\n",
        "            [\n",
        "                eye_retargeting_slider,\n",
        "                lip_retargeting_slider,\n",
        "                retargeting_input_image,\n",
        "                output_image,\n",
        "                output_image_paste_back\n",
        "            ],\n",
        "            value=\"🧹 Clear\"\n",
        "        )\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            with gr.Accordion(open=True, label=\"Retargeting Input\"):\n",
        "                retargeting_input_image.render()\n",
        "        with gr.Column():\n",
        "            with gr.Accordion(open=True, label=\"Retargeting Result\"):\n",
        "                output_image.render()\n",
        "        with gr.Column():\n",
        "            with gr.Accordion(open=True, label=\"Paste-back Result\"):\n",
        "                output_image_paste_back.render()\n",
        "    # binding functions for buttons\n",
        "    process_button_retargeting.click(\n",
        "        fn=gradio_pipeline.execute_image,\n",
        "        inputs=[eye_retargeting_slider, lip_retargeting_slider],\n",
        "        outputs=[output_image, output_image_paste_back],\n",
        "        show_progress=True\n",
        "    )\n",
        "    process_button_animation.click(\n",
        "        fn=gradio_pipeline.execute_video,\n",
        "        inputs=[\n",
        "            image_input,\n",
        "            video_input,\n",
        "            flag_relative_input,\n",
        "            flag_do_crop_input,\n",
        "            flag_remap_input\n",
        "        ],\n",
        "        outputs=[output_video, output_video_concat],\n",
        "        show_progress=True\n",
        "    )\n",
        "    image_input.change(\n",
        "        fn=gradio_pipeline.prepare_retargeting,\n",
        "        inputs=image_input,\n",
        "        outputs=[eye_retargeting_slider, lip_retargeting_slider, retargeting_input_image]\n",
        "    )\n",
        "\n",
        "##########################################################\n",
        "demo.launch(share=True)\n",
        "# demo.launch(\n",
        "#     server_name=args.server_name,\n",
        "#     server_port=args.server_port,\n",
        "#     share=args.share,\n",
        "# )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "cellView": "form",
        "id": "bKWqzimUR6Ht",
        "outputId": "de1aef2d-cd81-4f56-d8dc-d419a1575ced"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[15:22:08]\u001b[0m\u001b[2;36m \u001b[0mLoad appearance_feature_extractor done.                                      \u001b]8;id=247604;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=464277;file:///content/LivePortrait/src/live_portrait_wrapper.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:22:08] </span>Load appearance_feature_extractor done.                                      <a href=\"file:///content/LivePortrait/src/live_portrait_wrapper.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">live_portrait_wrapper.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///content/LivePortrait/src/live_portrait_wrapper.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad motion_extractor done.                                                  \u001b]8;id=731075;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=401031;file:///content/LivePortrait/src/live_portrait_wrapper.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Load motion_extractor done.                                                  <a href=\"file:///content/LivePortrait/src/live_portrait_wrapper.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">live_portrait_wrapper.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///content/LivePortrait/src/live_portrait_wrapper.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[15:22:09]\u001b[0m\u001b[2;36m \u001b[0mLoad warping_module done.                                                    \u001b]8;id=269527;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=974047;file:///content/LivePortrait/src/live_portrait_wrapper.py#41\u001b\\\u001b[2m41\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:22:09] </span>Load warping_module done.                                                    <a href=\"file:///content/LivePortrait/src/live_portrait_wrapper.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">live_portrait_wrapper.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///content/LivePortrait/src/live_portrait_wrapper.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[15:22:10]\u001b[0m\u001b[2;36m \u001b[0mLoad spade_generator done.                                                   \u001b]8;id=381163;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=871146;file:///content/LivePortrait/src/live_portrait_wrapper.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:22:10] </span>Load spade_generator done.                                                   <a href=\"file:///content/LivePortrait/src/live_portrait_wrapper.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">live_portrait_wrapper.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///content/LivePortrait/src/live_portrait_wrapper.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad stitching_retargeting_module done.                                      \u001b]8;id=635168;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=692955;file:///content/LivePortrait/src/live_portrait_wrapper.py#48\u001b\\\u001b[2m48\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Load stitching_retargeting_module done.                                      <a href=\"file:///content/LivePortrait/src/live_portrait_wrapper.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">live_portrait_wrapper.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///content/LivePortrait/src/live_portrait_wrapper.py#48\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLandmarkRunner warmup time: \u001b[1;36m0.\u001b[0m179s                                                 \u001b]8;id=529770;file:///content/LivePortrait/src/utils/landmark_runner.py\u001b\\\u001b[2mlandmark_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=884105;file:///content/LivePortrait/src/utils/landmark_runner.py#89\u001b\\\u001b[2m89\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>LandmarkRunner warmup time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>179s                                                 <a href=\"file:///content/LivePortrait/src/utils/landmark_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">landmark_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///content/LivePortrait/src/utils/landmark_runner.py#89\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">89</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mFaceAnalysisDIY warmup time: \u001b[1;36m0.\u001b[0m328s                                              \u001b]8;id=202834;file:///content/LivePortrait/src/utils/face_analysis_diy.py\u001b\\\u001b[2mface_analysis_diy.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=275087;file:///content/LivePortrait/src/utils/face_analysis_diy.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>FaceAnalysisDIY warmup time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>328s                                              <a href=\"file:///content/LivePortrait/src/utils/face_analysis_diy.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">face_analysis_diy.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///content/LivePortrait/src/utils/face_analysis_diy.py#79\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">79</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:1005: UserWarning: Expected at least 3 arguments for function <bound method GradioPipeline.execute_image of <src.gradio_pipeline.GradioPipeline object at 0x7b9aafc2b760>>, received 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:1001: UserWarning: Expected 6 arguments for function <bound method GradioPipeline.execute_video of <src.gradio_pipeline.GradioPipeline object at 0x7b9aafc2b760>>, received 5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:1005: UserWarning: Expected at least 6 arguments for function <bound method GradioPipeline.execute_video of <src.gradio_pipeline.GradioPipeline object at 0x7b9aafc2b760>>, received 5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://1a4690d7b5f27a9079.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1a4690d7b5f27a9079.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}